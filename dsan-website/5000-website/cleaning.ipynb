{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tabular cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cleaning NBA combine data\n",
        "\n",
        "I cleaned this data with the intent to merge it with NBA player season data. The first thing I had to do with the NBA combine data was adjust the format of the player name column. I changed the format from (Last, First) to (First Last) using strsplit and sapply in R. I also changed the name of the column from \"PLAYER\" to \"Name\" so that can merge the dataset by \"Name\". I then renamed some other columns to be more clear, and dropped those that were not needed. This dataset was relatively clean to begin with, so only a few minor adjustments were needed. \n",
        "\n",
        "[Link to code](https://github.com/anly501/dsan-5000-project-thm12/blob/main/codes/01-data-gathering/data_gathering%26cleaning.Rmd)\n",
        "\n",
        "[Link to data](https://github.com/anly501/dsan-5000-project-thm12/blob/main/data/01-modified-data/cleaned_nba_combine.csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cleaning NBA player season \n",
        "\n",
        "I cleaned and subsetting the  NBA player season data to merge it with the combine data. The dataset had duplicate player values for each season. I subsetted the data to only keep one value for each player in order to merge with the NBA combine dataset. I wanted to keep the version of each player in which they had their best season. I did this by keeping the version of each player that had the the most points for the season. Points are generally the most important stat in basketball, and while assists and rebounds are important, total points should be a good indicator of a season in which a player had one of their best years and remained healthy enough to play most of the season. I then deleted a pleathura of columns that would not be useful in indicating in game performance.\n",
        "\n",
        "[Link to code](https://github.com/anly501/dsan-5000-project-thm12/blob/main/codes/01-data-gathering/data_gathering%26cleaning.Rmd)\n",
        "\n",
        "[Link to data](https://github.com/anly501/dsan-5000-project-thm12/blob/main/data/01-modified-data/cleaned_best_NBA_season_player.csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Merging NBA combine and player season data\n",
        "\n",
        "I then merged the subset player season dataset with the NBA combine dataset. I used a full join by Player name in R. I then removed values that did not have combine data by removing rows that did not have a value for \"combine_year\".\n",
        "\n",
        "[Link to code](https://github.com/anly501/dsan-5000-project-thm12/blob/main/codes/01-data-gathering/data_gathering%26cleaning.Rmd)\n",
        "\n",
        "[Link to data](https://github.com/anly501/dsan-5000-project-thm12/blob/main/data/01-modified-data/cleaned_NBA_combined.csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cleaning Olympic Track and Field data\n",
        "\n",
        "The Olympic Track and Field dataset was already pretty clean, so I just created a subset that only included the High jump event. I then renamed the result column to Best Height (m).\n",
        "\n",
        "[Link to data](https://github.com/anly501/dsan-5000-project-thm12/blob/main/data/01-modified-data/cleaned_high_jump.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Gender            Event     Location  Year Medal                  Name  \\\n",
            "1199      M    High Jump Men          Rio  2016     G          Derek DROUIN   \n",
            "1200      M    High Jump Men          Rio  2016     S    Mutaz Essa BARSHIM   \n",
            "1201      M    High Jump Men          Rio  2016     B     Bohdan BONDARENKO   \n",
            "1202      M    High Jump Men      Beijing  2008     G         Andrey SILNOV   \n",
            "1203      M    High Jump Men      Beijing  2008     S        Germaine MASON   \n",
            "...     ...              ...          ...   ...   ...                   ...   \n",
            "2204      W  High Jump Women       London  1948     S          Dorothy ODAM   \n",
            "2205      W  High Jump Women       London  1948     B  Micheline OSTERMEYER   \n",
            "2206      W  High Jump Women  Los Angeles  1932     G           Jean SHILEY   \n",
            "2207      W  High Jump Women  Los Angeles  1932     S     Mildred DIDRIKSON   \n",
            "2208      W  High Jump Women  Los Angeles  1932     B             Eva DAWES   \n",
            "\n",
            "     Nationality  Best Height (m)  Unnamed: 8  \n",
            "1199         CAN             2.38         NaN  \n",
            "1200         QAT             2.36         NaN  \n",
            "1201         UKR             2.33         NaN  \n",
            "1202         RUS             2.36         NaN  \n",
            "1203         GBR             2.34         NaN  \n",
            "...          ...              ...         ...  \n",
            "2204         GBR             1.68         NaN  \n",
            "2205         FRA             1.61         NaN  \n",
            "2206         USA             1.65         NaN  \n",
            "2207         USA             1.65         NaN  \n",
            "2208         CAN              1.6         NaN  \n",
            "\n",
            "[107 rows x 9 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#subset track data\n",
        "olympic_track= pd.read_csv(\"../../data/00-raw-data/olympic_track.csv\")\n",
        "high_jump = olympic_track[olympic_track[\"Event\"].str.contains(\"High Jump\", case=False, na=False)]\n",
        "high_jump = high_jump.rename(columns={\"Result\": \" Best Height (m)\"})\n",
        "\n",
        "high_jump.to_csv(\"../../data/01-modified-data/cleaned_high_jump.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cleaning NFL combine data\n",
        "\n",
        "The NFL combine data was also already pretty clean, so I only made a few adjustments. I discarded values that did not have a result for standing vertical jump. Some prospects opt out of certain events and tests, but I am really only interested at looking at vertical jump for comparison to NBA prospests, so the prospects who did not test for that event were removed from the dataset. I then disarded values that served as dataset IDs and therefore had no significance for analysis. I finally changed the column name for \"Vertical\" to \"STANDING.VERTICAL\" so it will be easier to join and conduct analysis with the NBA combine dataset in the future.\n",
        "\n",
        "\n",
        "[Link to code](https://github.com/anly501/dsan-5000-project-thm12/blob/main/codes/01-data-gathering/data_gathering%26cleaning.Rmd)\n",
        "\n",
        "[Link to data](https://github.com/anly501/dsan-5000-project-thm12/blob/main/data/01-modified-data/cleaned_NFL_combine.csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cleaning Stretching Study data\n",
        "\n",
        "For the stretching data I changed the column \"Serial\\n No.\" to \"Participant number\", and then changed the values in the gender column to Male or Female rather than 1 or 2.\n",
        "\n",
        "\n",
        "[Link to data](https://github.com/anly501/dsan-5000-project-thm12/blob/main/data/01-modified-data/cleaned_stretching.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Participant number  Group  Age  Gender  Height ( Cm )  Weight ( Kg )   BMI  \\\n",
            "0                   1      1   21    Male         172.72             68  22.8   \n",
            "1                   2      1   23    Male         190.50             98  27.0   \n",
            "2                   3      1   21    Male         180.30             74  22.8   \n",
            "3                   4      1   19  Female         162.50             70  27.2   \n",
            "4                   5      1   20  Female         162.50             52  19.7   \n",
            "\n",
            "   Vertical jump\\n height ( Pre ) ( Cm )  \\\n",
            "0                                     39   \n",
            "1                                     32   \n",
            "2                                     49   \n",
            "3                                     24   \n",
            "4                                     27   \n",
            "\n",
            "   Vertical jump\\n height ( Post ) ( Cm )  \n",
            "0                                    37.5  \n",
            "1                                    35.0  \n",
            "2                                    48.0  \n",
            "3                                    24.0  \n",
            "4                                    26.0  \n"
          ]
        }
      ],
      "source": [
        "#clean stretching data\n",
        "stretching= pd.read_csv(\"../../data/00-raw-data/stretching.csv\")\n",
        "stretching = stretching.rename(columns={\"Serial\\n No.\": \"Participant number\"})\n",
        "stretching[\"Gender\"] = stretching[\"Gender\"].replace({1: \"Male\", 2: \"Female\"})\n",
        "\n",
        "stretching.to_csv(\"../../data/01-modified-data/cleaned_stretching.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Text cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wikipedia APi data cleaning\n",
        "\n",
        "\n",
        "I cleaned the text data by turning the text into a corpus and list of tokens, I then cleaned the tokens by lemmatizing them and removing digits. I also added written out numbers to the list of stopwords. I then vectorized the tokens and created a sparse matix of the tokens as well as an array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "vocabulary =  {'basketball': 146, 'team': 1602, 'sport': 1511, 'commonly': 292, 'player': 1199, 'opposing': 1111, 'another': 78, 'rectangular': 1308, 'court': 339, 'compete': 296, 'primary': 1242, 'objective': 1087, 'shooting': 1450, 'approximately': 85, 'inch': 783, 'cm': 268, 'diameter': 413, 'defender': 384, 'hoop': 753, 'basket': 145, 'mounted': 1037, 'foot': 613, 'high': 738, 'backboard': 129, 'end': 500, 'preventing': 1240, 'field': 584, 'goal': 682, 'worth': 1793, 'point': 1204, 'unless': 1698, 'made': 953, 'behind': 152, 'line': 926, 'foul': 627, 'timed': 1638, 'play': 1197, 'stop': 1548, 'fouled': 628, 'designated': 400, 'shoot': 1448, 'technical': 1606, 'given': 675, 'free': 635, 'throw': 1629, 'game': 652, 'win': 1780, 'regulation': 1324, 'expires': 553, 'score': 1403, 'tied': 1634, 'additional': 24, 'period': 1175, 'overtime': 1136, 'mandated': 967, 'players': 1200, 'advance': 27, 'ball': 137, 'bouncing': 183, 'walking': 1748, 'running': 1389, 'dribbling': 464, 'passing': 1155, 'teammate': 1603, 'require': 1346, 'considerable': 309, 'skill': 1470, 'offense': 1094, 'may': 985, 'use': 1709, 'variety': 1721, 'shot': 1455, 'layup': 899, 'jump': 860, 'dunk': 469, 'defense': 386, 'steal': 1538, 'dribbler': 463, 'intercept': 825, 'pass': 1152, 'block': 168, 'either': 488, 'collect': 274, 'rebound': 1289, 'missed': 1022, 'bounce': 182, 'rim': 1368, 'violation': 1736, 'lift': 919, 'drag': 457, 'pivot': 1189, 'without': 1784, 'carry': 215, 'hold': 747, 'hand': 718, 'resume': 1359, 'side': 1457, 'fall': 566, 'playing': 1201, 'position': 1213, 'tallest': 1597, 'usually': 1713, 'center': 223, 'second': 1413, 'strongest': 1560, 'power': 1224, 'forward': 626, 'slightly': 1474, 'shorter': 1452, 'agile': 40, 'small': 1476, 'shortest': 1453, 'best': 158, 'handler': 721, 'guard': 703, 'implement': 775, 'coach': 269, 'plan': 1192, 'managing': 966, 'execution': 546, 'offensive': 1095, 'defensive': 387, 'positioning': 1214, 'informally': 807, 'invented': 839, 'canadian': 210, 'american': 69, 'gym': 708, 'teacher': 1601, 'james': 849, 'naismith': 1051, 'springfield': 1517, 'massachusetts': 980, 'united': 1696, 'states': 1532, 'ha': 710, 'evolved': 536, 'become': 149, 'world': 1791, 'popular': 1208, 'widely': 1777, 'viewed': 1734, 'national': 1057, 'association': 103, 'nba': 1062, 'significant': 1459, 'professional': 1249, 'league': 903, 'term': 1615, 'popularity': 1209, 'salary': 1395, 'talent': 1594, 'level': 917, 'competition': 300, 'drawing': 458, 'u': 1686, 'college': 275, 'outside': 1130, 'north': 1081, 'america': 68, 'top': 1649, 'club': 267, 'qualify': 1269, 'continental': 319, 'championship': 231, 'euroleague': 526, 'champions': 230, 'americas': 70, 'fiba': 582, 'cup': 360, 'men': 998, 'olympic': 1102, 'tournament': 1659, 'major': 958, 'international': 831, 'event': 531, 'attract': 115, 'around': 94, 'continent': 318, 'host': 759, 'regional': 1320, 'like': 922, 'eurobasket': 524, 'americup': 71, 'women': 1788, 'feature': 575, 'main': 956, 'wnba': 1786, 'ncaa': 1064, 'division': 440, 'also': 60, 'whereas': 1770, 'european': 528, 'participate': 1147, 'history': 745, 'creation': 346, 'december': 378, 'professor': 1250, 'physical': 1186, 'education': 482, 'instructor': 818, 'young': 1806, 'christian': 251, 'training': 1668, 'school': 1399, 'wa': 1746, 'trying': 1678, 'keep': 867, 'class': 259, 'active': 18, 'rainy': 1276, 'day': 373, 'sought': 1494, 'vigorous': 1735, 'indoor': 800, 'student': 1563, 'occupied': 1090, 'proper': 1257, 'fitness': 597, 'long': 935, 'new': 1074, 'england': 507, 'winter': 1782, 'rejecting': 1327, 'idea': 767, 'rough': 1382, 'poorly': 1207, 'suited': 1579, 'walled': 1750, 'gymnasium': 709, 'would': 1794, 'pas': 1151, 'try': 1677, 'tossing': 1651, 'wall': 1749, 'wrote': 1798, 'basic': 143, 'rule': 1386, 'nailed': 1050, 'peach': 1163, 'onto': 1106, 'elevated': 491, 'track': 1663, 'initially': 810, 'set': 1431, 'bottom': 181, 'intact': 821, 'meant': 989, 'retrieved': 1361, 'manually': 971, 'scored': 1406, 'quickly': 1275, 'proved': 1261, 'tedious': 1608, 'removed': 1336, 'allow': 52, 'poked': 1205, 'dowel': 452, 'originally': 1120, 'played': 1198, 'soccer': 1484, 'round': 1383, 'football': 614, 'time': 1637, 'lace': 885, 'close': 265, 'hole': 749, 'needed': 1068, 'inserting': 814, 'inflatable': 803, 'bladder': 166, 'sewn': 1436, 'together': 1645, 'segment': 1419, 'cover': 341, 'flipped': 603, 'could': 336, 'cause': 221, 'unpredictable': 1702, 'eventually': 532, 'construction': 315, 'method': 1006, 'change': 234, 'endorsed': 504, 'advantageous': 30, 'gripping': 699, 'remains': 1335, 'first': 595, 'specifically': 1502, 'brown': 197, 'late': 892, 'tony': 1647, 'hinkle': 742, 'searching': 1411, 'visible': 1739, 'spectator': 1505, 'alike': 49, 'introduced': 837, 'orange': 1114, 'common': 291, 'part': 1145, 'original': 1119, 'except': 541, 'mean': 987, 'movement': 1039, 'limited': 925, 'asymmetric': 105, 'shape': 1440, 'early': 475, 'double': 451, 'dribble': 461, 'used': 1710, 'finally': 591, 'replaced': 1341, 'metal': 1004, 'soon': 1490, 'merely': 1000, 'passed': 1153, 'whenever': 1769, 'person': 1178, 'got': 688, 'gain': 649, 'whichever': 1772, 'mezzanine': 1008, 'balcony': 136, 'impractical': 780, 'began': 151, 'interfere': 828, 'prevent': 1239, 'interference': 829, 'effect': 484, 'allowing': 54, 'handwritten': 723, 'diary': 415, 'discovered': 430, 'granddaughter': 693, 'indicate': 796, 'nervous': 1070, 'incorporated': 790, 'child': 245, 'called': 205, 'duck': 466, 'rock': 1373, 'many': 973, 'failed': 564, 'frank': 633, 'mahan': 955, 'approached': 84, 'christmas': 252, 'break': 191, 'asking': 99, 'intended': 823, 'call': 204, 'replied': 1343, 'n': 1048, 'thought': 1624, 'focused': 608, 'getting': 669, 'started': 1528, 'suggested': 1578, 'laughed': 897, 'saying': 1397, 'name': 1052, 'kill': 874, 'said': 1394, 'seems': 1417, 'good': 686, 'official': 1097, 'ymca': 1803, 'albany': 47, 'york': 1805, 'january': 850, 'ended': 501, 'half': 712, 'size': 1469, 'present': 1236, 'streetball': 1556, 'increased': 792, 'weather': 1758, 'icy': 766, 'taken': 1593, 'indoors': 801, 'convenient': 330, 'split': 1508, 'became': 148, 'standard': 1523, 'adherent': 25, 'dispatched': 432, 'ymcas': 1804, 'throughout': 1628, 'spread': 1515, 'canada': 209, 'well': 1763, 'established': 520, 'several': 1435, 'woman': 1787, 'responsible': 1354, 'developing': 409, 'spreading': 1516, 'within': 1783, 'decade': 377, 'discouraged': 429, 'rowdy': 1384, 'crowd': 356, 'detract': 407, 'mission': 1023, 'however': 761, 'amateur': 67, 'filled': 588, 'void': 1744, 'year': 1802, 'war': 1752, 'athletic': 108, 'union': 1694, 'intercollegiate': 826, 'forerunner': 615, 'vied': 1733, 'control': 325, 'pro': 1246, 'formed': 621, 'protect': 1260, 'exploitation': 554, 'promote': 1253, 'le': 900, 'lasted': 891, 'instrumental': 819, 'establishing': 521, 'colleague': 273, 'c': 201, 'beamis': 147, 'fielded': 585, 'suburban': 1569, 'pittsburgh': 1188, 'geneva': 662, 'later': 893, 'coached': 270, 'university': 1697, 'kansas': 864, 'handing': 719, 'rein': 1325, 'renowned': 1338, 'forrest': 624, 'phog': 1185, 'allen': 50, 'disciple': 427, 'amos': 73, 'alonzo': 59, 'stagg': 1521, 'brought': 196, 'chicago': 243, 'adolph': 26, 'rupp': 1390, 'enjoyed': 509, 'great': 694, 'success': 1571, 'kentucky': 869, 'february': 578, 'hamline': 716, 'agriculture': 41, 'affiliated': 34, 'minnesota': 1017, 'including': 789, 'columbia': 280, 'cornell': 334, 'dartmouth': 371, 'naval': 1060, 'academy': 7, 'colorado': 279, 'yale': 1801, 'sponsoring': 1510, 'frequent': 637, 'injury': 812, 'prompted': 1255, 'president': 1238, 'theodore': 1619, 'roosevelt': 1380, 'suggest': 1577, 'form': 617, 'governing': 689, 'body': 173, 'resulting': 1358, 'iaaus': 765, 'changed': 235, 'collegiate': 277, 'interuniversity': 835, 'kingston': 875, 'ontario': 1105, 'mcgill': 986, 'alma': 56, 'mater': 982, 'visited': 1741, 'queen': 1272, 'minute': 1020, 'settled': 1433, 'outcome': 1124, 'turnout': 1680, 'watched': 1753, 'still': 1546, 'exists': 551, 'athletics': 109, 'naia': 1049, 'organized': 1117, 'invitation': 840, 'nit': 1078, 'rocked': 1374, 'gambling': 651, 'scandal': 1398, 'dozen': 454, 'implicated': 776, 'match': 981, 'fixing': 598, 'shaving': 1442, 'partially': 1146, 'spurred': 1519, 'cheating': 239, 'lost': 944, 'support': 1583, 'widespread': 1778, 'district': 438, 'consolidation': 313, 'far': 571, 'smaller': 1477, 'counterpart': 337, 'th': 1618, 'century': 225, 'ideal': 768, 'interscholastic': 834, 'due': 467, 'modest': 1027, 'equipment': 515, 'personnel': 1180, 'requirement': 1347, 'television': 1610, 'coverage': 342, 'unrivaled': 1703, 'perhaps': 1173, 'legendary': 913, 'indiana': 795, 'franklin': 634, 'wonder': 1789, 'took': 1648, 'nation': 1056, 'storm': 1552, 'dominating': 447, 'earning': 477, 'recognition': 1299, 'today': 1644, 'virtually': 1738, 'every': 534, 'varsity': 1723, 'rural': 1391, 'area': 90, 'identification': 769, 'entire': 512, 'community': 295, 'larger': 888, 'known': 878, 'go': 681, 'higher': 739, 'graduation': 692, 'season': 1412, 'boy': 188, 'girl': 673, 'represented': 1344, 'according': 11, 'federation': 579, 'state': 1530, 'associations': 104, 'illinois': 772, 'particularly': 1150, 'resident': 1351, 'devotion': 412, 'hoosier': 755, 'hysteria': 764, 'critically': 351, 'acclaimed': 8, 'film': 589, 'hoosiers': 756, 'show': 1456, 'depth': 395, 'meaning': 988, 'currently': 364, 'determine': 405, 'champion': 229, 'serious': 1429, 'effort': 487, 'sent': 1424, 'mostly': 1034, 'midwest': 1013, 'affair': 33, 'grew': 698, 'faced': 562, 'opposition': 1113, 'central': 224, 'colleges': 276, 'schools': 1400, 'bore': 178, 'threat': 1625, 'losing': 942, 'accreditation': 12, 'last': 890, 'organization': 1115, 'concerned': 305, 'recruit': 1307, 'prep': 1234, 'rank': 1281, 'invite': 842, 'minority': 1019, 'private': 1245, 'parochial': 1144, 'catholic': 220, 'ran': 1278, 'loyola': 948, 'invitational': 841, 'series': 1428, 'venue': 1728, 'georgetown': 666, 'george': 665, 'mason': 979, 'black': 165, 'held': 734, 'hampton': 717, 'institute': 816, 'starting': 1529, 'tuskegee': 1682, 'following': 612, 'pause': 1161, 'ii': 770, 'resumed': 1360, 'tennessee': 1614, 'nashville': 1055, 'basis': 144, 'dwindled': 472, 'v': 1714, 'board': 171, 'integration': 822, 'alabama': 46, 'teams': 1604, 'abounded': 5, 'hundred': 762, 'town': 1662, 'city': 257, 'little': 932, 'jumped': 861, 'armory': 93, 'smoky': 1481, 'dance': 369, 'hall': 715, 'leagues': 904, 'came': 207, 'went': 1765, 'barnstorming': 139, 'squad': 1520, 'celtics': 222, 'african': 37, 'renaissance': 1337, 'rens': 1339, 'existing': 550, 'harlem': 727, 'globetrotters': 679, 'tour': 1656, 'baa': 126, 'toronto': 1650, 'huskies': 763, 'knickerbockers': 876, 'november': 1083, 'merged': 1001, 'nbl': 1063, 'thus': 1633, 'paving': 1162, 'way': 1755, 'growth': 702, 'interest': 827, 'fame': 568, 'founded': 631, 'site': 1467, 'roster': 1381, 'include': 786, 'referee': 1313, 'people': 1167, 'contributed': 324, 'significantly': 1460, 'development': 410, 'accomplished': 10, 'career': 214, 'upstart': 1706, 'emerged': 495, 'briefly': 193, 'threatened': 1626, 'dominance': 444, 'aba': 1, 'merger': 1002, 'featured': 576, 'famous': 569, 'mikan': 1014, 'big': 162, 'man': 964, 'handling': 722, 'wizard': 1785, 'bob': 172, 'cousy': 340, 'genius': 663, 'bill': 163, 'russell': 1392, 'boston': 179, 'charismatic': 237, 'wilt': 1779, 'chamberlain': 228, 'star': 1527, 'oscar': 1122, 'robertson': 1372, 'jerry': 851, 'west': 1766, 'recent': 1296, 'kareem': 865, 'abdul': 2, 'jabbar': 848, 'shaquille': 1441, 'neal': 1065, 'hakeem': 711, 'olajuwon': 1100, 'karl': 866, 'malone': 963, 'playmaker': 1202, 'john': 854, 'stockton': 1547, 'isiah': 845, 'thomas': 1622, 'steve': 1545, 'nash': 1054, 'pleasing': 1203, 'julius': 859, 'erving': 516, 'charles': 238, 'barkley': 138, 'dirk': 424, 'nowitzki': 1084, 'pau': 1160, 'gasol': 654, 'parker': 1143, 'latin': 894, 'manu': 970, 'ginobili': 672, 'superstar': 1582, 'iverson': 847, 'kobe': 879, 'bryant': 198, 'tim': 1636, 'duncan': 468, 'lebron': 910, 'stephen': 1543, 'curry': 365, 'giannis': 671, 'antetokounmpo': 80, 'etc': 522, 'credit': 347, 'ushering': 1711, 'highest': 740, 'larry': 889, 'bird': 164, 'earvin': 478, 'magic': 954, 'johnson': 855, 'michael': 1010, 'jordan': 857, 'developmental': 411, 'g': 648, 'branding': 189, 'deal': 376, 'gatorade': 656, 'founding': 632, 'argentina': 91, 'czechoslovakia': 368, 'greece': 696, 'italy': 846, 'latvia': 896, 'portugal': 1212, 'romania': 1378, 'switzerland': 1589, 'oversaw': 1134, 'acronym': 14, 'derived': 396, 'french': 636, 'fédération': 647, 'internationale': 832, 'de': 374, 'included': 787, 'berlin': 157, 'summer': 1580, 'olympics': 1103, 'although': 65, 'demonstration': 393, 'defeated': 380, 'final': 590, 'outdoors': 1125, 'dominated': 446, 'whose': 1775, 'title': 1643, 'controversial': 328, 'munich': 1043, 'soviet': 1497, 'ending': 502, 'replayed': 1342, 'chile': 246, 'added': 23, 'montreal': 1033, 'quebec': 1271, 'brazil': 190, 'australia': 117, 'rivaling': 1371, 'allowed': 53, 'prior': 1244, 'south': 1496, 'continued': 320, 'introduction': 838, 'dream': 460, 'athens': 106, 'suffered': 1575, 'loss': 943, 'using': 1712, 'falling': 567, 'puerto': 1265, 'rico': 1364, 'lithuania': 930, 'group': 701, 'eliminated': 492, 'semifinal': 1421, 'bronze': 195, 'medal': 994, 'defeating': 381, 'finishing': 594, 'redeem': 1310, 'gold': 684, 'b': 125, 'turkey': 1679, 'despite': 404, 'featuring': 577, 'worldwide': 1792, 'age': 38, 'global': 677, 'reflected': 1317, 'nationality': 1058, 'inhabited': 809, 'coming': 285, 'mid': 1011, 'croatians': 353, 'dražen': 459, 'petrović': 1181, 'toni': 1646, 'kukoč': 884, 'serbian': 1427, 'vlade': 1743, 'divac': 439, 'lithuanians': 931, 'arvydas': 97, 'sabonis': 1393, 'šarūnas': 1810, 'marčiulionis': 978, 'dutchman': 471, 'rik': 1367, 'smits': 1480, 'german': 667, 'detlef': 406, 'schrempf': 1401, 'philippines': 1183, 'philippine': 1182, 'april': 86, 'araneta': 87, 'coliseum': 272, 'cubao': 359, 'quezon': 1273, 'rebellion': 1288, 'defunct': 389, 'manila': 968, 'industrial': 802, 'commercial': 287, 'tightly': 1635, 'controlled': 326, 'recognized': 1300, 'micaa': 1009, 'participated': 1148, 'opened': 1107, 'pre': 1227, 'eminent': 496, 'commenced': 286, 'september': 1426, 'completion': 304, 'month': 1032, 'shift': 1444, 'current': 363, 'format': 620, 'october': 1093, 'attempt': 111, 'avoid': 120, 'competing': 299, 'directly': 423, 'various': 1722, 'code': 271, 'zealand': 1808, 'luc': 949, 'longley': 937, 'andrew': 75, 'gaze': 658, 'shane': 1439, 'heal': 730, 'chris': 250, 'anstey': 79, 'bogut': 175, 'internationally': 833, 'becoming': 150, 'poster': 1221, 'figure': 586, 'smith': 1479, 'senda': 1422, 'berenson': 155, 'modified': 1028, 'shortly': 1454, 'hired': 743, 'learn': 906, 'fascinated': 573, 'value': 1715, 'teach': 1600, 'march': 975, 'freshman': 639, 'sophomore': 1492, 'interinstitutional': 830, 'california': 203, 'miss': 1021, 'head': 728, 'published': 1264, 'editor': 480, 'spalding': 1498, 'guide': 707, 'mount': 1036, 'holyoke': 750, 'sophie': 1491, 'newcomb': 1075, 'clara': 258, 'gregory': 697, 'baer': 134, 'across': 15, 'country': 338, 'wellesley': 1764, 'vassar': 1726, 'bryn': 199, 'mawr': 984, 'stanford': 1525, 'berkeley': 156, 'victory': 1732, 'structured': 1562, 'executive': 547, 'committee': 290, 'rules': 1387, 'created': 344, 'per': 1168, 'sports': 1513, 'backed': 131, 'complete': 302, 'edmonton': 481, 'grads': 690, 'touring': 1658, 'based': 141, 'alberta': 48, 'operated': 1108, 'toured': 1657, 'exceptionally': 542, 'successful': 1572, 'posted': 1220, 'record': 1302, 'span': 1499, 'met': 1003, 'wanted': 1751, 'challenge': 227, 'funding': 646, 'gate': 655, 'receipt': 1291, 'shone': 1447, 'exhibition': 549, 'trip': 1676, 'europe': 527, 'consecutive': 308, 'unpaid': 1701, 'remain': 1333, 'single': 1466, 'style': 1564, 'overly': 1133, 'emphasizing': 498, 'individual': 799, 'aau': 0, 'chosen': 249, 'sprang': 1514, 'producing': 1248, 'athlete': 107, 'babe': 127, 'didrikson': 416, 'golden': 685, 'cyclones': 367, 'red': 1309, 'heads': 729, 'competed': 297, 'though': 1623, 'shaky': 1438, 'attendance': 114, 'marquee': 977, 'lisa': 928, 'leslie': 915, 'diana': 414, 'taurasi': 1599, 'candace': 212, 'among': 72, 'others': 1123, 'helped': 736, 'folded': 609, 'looked': 939, 'niche': 1077, 'recently': 1297, 'step': 1542, 'june': 863, 'signed': 1458, 'contract': 323, 'extension': 557, 'espn': 517, 'along': 58, 'ever': 533, 'right': 1366, 'fee': 580, 'paid': 1140, 'million': 1016, 'dollar': 443, 'dispersed': 433, 'article': 96, 'commissioner': 288, 'david': 372, 'stern': 1544, 'bad': 133, 'economy': 479, 'profitable': 1251, 'lot': 945, 'money': 1031, 'large': 887, 'number': 1085, 'budgeting': 200, 'even': 530, 'measurements': 992, 'limit': 924, 'discussed': 431, 'section': 1414, 'often': 1099, 'vary': 1724, 'object': 1086, 'outscore': 1129, 'opponent': 1109, 'throwing': 1630, 'beyond': 160, 'arc': 88, 'metre': 1007, 'ft': 641, 'earned': 476, 'awarded': 122, 'non': 1079, 'scoring': 1407, 'endline': 503, 'games': 653, 'quarter': 1270, 'varies': 1720, 'length': 914, 'exchange': 544, 'actual': 21, 'clock': 264, 'stopped': 1550, 'therefore': 1620, 'generally': 661, 'take': 1592, 'much': 1041, 'longer': 936, 'allotted': 51, 'typically': 1685, 'hour': 760, 'substitutions': 1568, 'unlimited': 1699, 'done': 448, 'oversees': 1135, 'strategy': 1555, 'assistant': 102, 'manager': 965, 'statistician': 1534, 'doctor': 441, 'trainer': 1667, 'uniform': 1693, 'consists': 312, 'pair': 1142, 'short': 1451, 'jersey': 852, 'clearly': 262, 'unique': 1695, 'printed': 1243, 'front': 640, 'back': 128, 'wear': 1757, 'sneaker': 1483, 'provide': 1262, 'extra': 559, 'ankle': 77, 'sponsor': 1509, 'stoppage': 1549, 'requested': 1345, 'sometimes': 1488, 'meeting': 996, 'televised': 1609, 'consisting': 311, 'referred': 1316, 'crew': 348, 'chief': 244, 'umpire': 1688, 'table': 1591, 'total': 1652, 'keeping': 868, 'timekeeping': 1639, 'substitution': 1567, 'possession': 1217, 'arrow': 95, 'essential': 518, 'flat': 600, 'surface': 1586, 'opposite': 1112, 'competitive': 301, 'sheet': 1443, 'scoreboard': 1404, 'alternating': 63, 'whistle': 1773, 'system': 1590, 'meter': 1005, 'wide': 1776, 'wood': 1790, 'flooring': 605, 'constructed': 314, 'maple': 974, 'plank': 1193, 'direction': 421, 'dimension': 420, 'logo': 934, 'home': 751, 'painted': 1141, 'circle': 253, 'steel': 1540, 'attached': 110, 'net': 1071, 'affixed': 35, 'measure': 990, 'white': 1774, 'outlined': 1128, 'box': 187, 'almost': 57, 'exactly': 537, 'inside': 815, 'baseline': 142, 'variation': 1717, 'possible': 1218, 'considered': 310, 'important': 778, 'correct': 335, 'height': 733, 'adverse': 31, 'must': 1047, 'check': 240, 'momentarily': 1030, 'aid': 42, 'visual': 1742, 'confirmation': 307, 'act': 16, 'checking': 241, 'advantage': 29, 'slowing': 1475, 'doe': 442, 'regulated': 1323, 'circumference': 254, 'weighs': 1761, 'oz': 1137, 'weight': 1762, 'x': 1799, 'formalized': 619, 'version': 1729, 'halfcourt': 713, 'dedicated': 379, 'mixed': 1024, 'violations': 1737, 'advanced': 28, 'toward': 1660, 'thrown': 1631, 'tapped': 1598, 'rolled': 1377, 'dribbled': 462, 'stay': 1536, 'touch': 1653, 'travel': 1672, 'bound': 184, 'forfeit': 616, 'boundary': 185, 'placed': 1190, 'result': 1357, 'infraction': 808, 'traveling': 1673, 'stopping': 1551, 'giving': 676, 'placing': 1191, 'carrying': 216, 'return': 1362, 'backcourt': 130, 'kicked': 872, 'struck': 1561, 'fist': 596, 'reset': 1350, 'imposed': 779, 'progressing': 1252, 'past': 1156, 'halfway': 714, 'sex': 1437, 'attempting': 113, 'holding': 748, 'closely': 266, 'guarded': 704, 'remaining': 1334, 'restricted': 1356, 'lane': 886, 'key': 870, 'designed': 402, 'help': 735, 'goaltending': 683, 'touching': 1655, 'downward': 453, 'flight': 602, 'related': 1328, 'reaching': 1284, 'committed': 289, 'awarding': 123, 'cancelling': 211, 'case': 217, 'fouls': 629, 'unfairly': 1691, 'disadvantage': 426, 'certain': 226, 'type': 1684, 'contact': 316, 'illegal': 771, 'personal': 1179, 'receive': 1292, 'inbounds': 782, 'depending': 394, 'whether': 1771, 'making': 961, 'attempted': 112, 'judging': 858, 'controversy': 329, 'calling': 206, 'category': 219, 'charged': 236, 'failure': 565, 'properly': 1258, 'scorebook': 1405, 'unsportsmanlike': 1704, 'conduct': 306, 'repeated': 1340, 'incident': 785, 'disqualification': 434, 'blatant': 167, 'involving': 844, 'excessive': 543, 'unnecessary': 1700, 'intentional': 824, 'flagrant': 599, 'ejection': 489, 'disqualifying': 435, 'exceeds': 540, 'subsequent': 1566, 'us': 1708, 'reach': 1283, 'shooter': 1449, 'regain': 1319, 'potentially': 1222, 'air': 43, 'specified': 1503, 'bonus': 177, 'signified': 1461, 'indicator': 798, 'light': 920, 'reading': 1286, 'penalty': 1165, 'illuminated': 773, 'directional': 422, 'dot': 450, 'indicating': 797, 'situation': 1468, 'wait': 1747, 'reclaim': 1298, 'continuing': 321, 'unsuccessful': 1705, 'equal': 514, 'regular': 1321, 'receives': 1294, 'combination': 282, 'colloquially': 278, 'technique': 1607, 'practice': 1225, 'positions': 1216, 'specify': 1504, 'whatsoever': 1767, 'evolution': 535, 'specific': 1501, 'trend': 1674, 'advocated': 32, 'mike': 1015, 'krzyzewski': 883, 'towards': 1661, 'positionless': 1215, 'allows': 55, 'description': 399, 'fastest': 574, 'organizes': 1118, 'controlling': 327, 'sure': 1585, 'get': 668, 'creates': 345, 'volume': 1745, 'mainly': 957, 'ranged': 1280, 'perimeter': 1174, 'primarily': 1241, 'via': 1731, 'cut': 366, 'penetration': 1166, 'seek': 1416, 'actively': 19, 'offensively': 1096, 'zone': 1809, 'flexible': 601, 'similar': 1463, 'responsibility': 1353, 'wing': 1781, 'post': 1219, 'describe': 397, 'occasion': 1089, 'choose': 248, 'different': 418, 'designation': 401, 'assigned': 101, 'manoeuver': 969, 'trap': 1671, 'varied': 1719, 'normally': 1080, 'planned': 1194, 'quick': 1274, 'legal': 912, 'guarding': 705, 'standing': 1524, 'next': 1076, 'screen': 1409, 'pick': 1187, 'combined': 283, 'roll': 1376, 'away': 124, 'screens': 1410, 'teamwork': 1605, 'lead': 901, 'always': 66, 'ensure': 510, 'predictable': 1229, 'occur': 1091, 'varying': 1725, 'face': 561, 'facing': 563, 'rest': 1355, 'fingertip': 593, 'dominant': 445, 'arm': 92, 'supporting': 1584, 'jumping': 862, 'extending': 556, 'fully': 643, 'extended': 555, 'wrist': 1795, 'bent': 154, 'stationary': 1533, 'moment': 1029, 'release': 1330, 'follow': 610, 'put': 1268, 'steady': 1537, 'backspin': 132, 'absorb': 6, 'impact': 774, 'trajectory': 1669, 'somewhat': 1489, 'recommended': 1301, 'redirect': 1311, 'described': 398, 'setup': 1434, 'preceded': 1228, 'crouching': 355, 'action': 17, 'preloads': 1232, 'muscle': 1045, 'increase': 791, 'straightens': 1554, 'neither': 1069, 'leaving': 909, 'floor': 604, 'released': 1331, 'near': 1066, 'provides': 1263, 'greater': 695, 'range': 1279, 'elevate': 490, 'requires': 1348, 'motion': 1035, 'lay': 898, 'underhand': 1690, 'finger': 592, 'percentage': 1169, 'accuracy': 13, 'slam': 1472, 'circus': 255, 'low': 946, 'heaved': 732, 'scooped': 1402, 'flung': 606, 'balance': 135, 'airborne': 44, 'chance': 233, 'completely': 303, 'hit': 746, 'jocularly': 853, 'brick': 192, 'hang': 724, 'make': 960, 'rebounding': 1290, 'successfully': 1573, 'role': 1375, 'recovered': 1305, 'defending': 385, 'loose': 941, 'majority': 959, 'tends': 1613, 'better': 159, 'recover': 1304, 'example': 539, 'moving': 1040, 'accompanied': 9, 'followed': 611, 'staple': 1526, 'chest': 242, 'passer': 1154, 'receiver': 1293, 'involves': 843, 'outward': 1131, 'snap': 1482, 'thumb': 1632, 'add': 22, 'velocity': 1727, 'leaf': 902, 'defence': 382, 'react': 1285, 'crisply': 350, 'thirds': 1621, 'strike': 1559, 'harder': 726, 'kicking': 873, 'deliberately': 391, 'crowded': 357, 'overhead': 1132, 'outlet': 1127, 'occurs': 1092, 'crucial': 358, 'aspect': 100, 'difficult': 419, 'know': 877, 'prefers': 1231, 'special': 1500, 'looking': 940, 'receiving': 1295, 'look': 938, 'implies': 777, 'perform': 1170, 'effectively': 486, 'discourage': 428, 'believing': 153, 'likely': 923, 'turnover': 1681, 'continuously': 322, 'push': 1267, 'ground': 700, 'rather': 1282, 'patting': 1159, 'ensures': 511, 'farthest': 572, 'able': 4, 'competently': 298, 'tend': 1612, 'reducing': 1312, 'distance': 436, 'frequently': 638, 'leg': 911, 'switch': 1588, 'suddenly': 1574, 'pattern': 1158, 'defend': 383, 'crossover': 354, 'effective': 485, 'move': 1038, 'skilled': 1471, 'watching': 1754, 'peripheral': 1176, 'vision': 1740, 'location': 933, 'focus': 607, 'opportunity': 1110, 'danger': 370, 'someone': 1487, 'blocking': 170, 'performed': 1172, 'succeeds': 1570, 'altering': 62, 'variant': 1716, 'path': 1157, 'touched': 1654, 'taller': 1596, 'timing': 1641, 'sufficiently': 1576, 'vertical': 1730, 'leap': 905, 'blocker': 169, 'male': 962, 'guards': 706, 'coordination': 332, 'smallest': 1478, 'tall': 1595, 'survey': 1587, 'average': 118, 'pound': 1223, 'kg': 871, 'manute': 972, 'bol': 176, 'gheorghe': 670, 'mureșan': 1044, 'margo': 976, 'dydek': 473, 'muggsy': 1042, 'bogues': 174, 'relatively': 1329, 'thrived': 1627, 'anthony': 81, 'spud': 1518, 'webb': 1759, 'temeka': 1611, 'rookie': 1379, 'award': 121, 'phoenix': 1184, 'mercury': 999, 'ability': 3, 'navigate': 1061, 'strength': 1557, 'regularly': 1322, 'inflate': 804, 'prospect': 1259, 'exaggerate': 538, 'appealing': 83, 'scout': 1408, 'prefer': 1230, 'stated': 1531, 'measured': 991, 'sam': 1396, 'former': 622, 'writer': 1796, 'tribune': 1675, 'sort': 1493, 'camp': 208, 'come': 284, 'mad': 952, 'hear': 731, 'agent': 39, 'file': 587, 'story': 1553, 'copy': 333, 'desk': 403, 'medium': 995, 'wrong': 1797, 'joke': 856, 'since': 1464, 'recorded': 1303, 'definitively': 388, 'measuring': 993, 'shoe': 1446, 'variations': 1718, 'activity': 20, 'superficial': 1581, 'distinct': 437, 'degree': 390, 'influence': 805, 'contest': 317, 'reinforce': 1326, 'earlier': 474, 'horseball': 758, 'horseback': 757, 'handled': 720, 'polo': 1206, 'rugby': 1385, 'donkey': 449, 'attracted': 116, 'criticism': 352, 'animal': 76, 'informal': 806, 'setting': 1432, 'strict': 1558, 'cleared': 261, 'cardiovascular': 213, 'stamen': 1522, 'need': 1067, 'run': 1388, 'forth': 625, 'full': 642, 'raise': 1277, 'conversely': 331, 'insufficient': 820, 'latter': 895, 'gradually': 691, 'gaining': 650, 'tested': 1616, 'asian': 98, 'macau': 950, 'youth': 1807, 'singapore': 1465, 'championships': 232, 'rimini': 1369, 'senior': 1423, 'highly': 741, 'tipped': 1642, 'page': 1139, 'subsection': 1565, 'emphasize': 497, 'stealing': 1539, 'hoops': 754, 'lowered': 947, 'originated': 1121, 'developed': 408, 'create': 343, 'altered': 61, 'unicycle': 1692, 'riding': 1365, 'particular': 1149, 'least': 908, 'pedal': 1164, 'bounding': 186, 'plastic': 1196, 'preserve': 1237, 'shin': 1445, 'spin': 1507, 'offs': 1098, 'separate': 1425, 'ringball': 1370, 'traditional': 1665, 'stem': 1541, 'promoted': 1254, 'africa': 36, 'namibia': 1053, 'botswana': 180, 'lesotho': 916, 'india': 794, 'mauritius': 983, 'establish': 519, 'korfball': 882, 'dutch': 470, 'korfbal': 881, 'korf': 880, 'netherlands': 1073, 'gender': 659, 'netball': 1072, 'anz': 82, 'premier': 1233, 'formerly': 623, 'exclusively': 545, 'slamball': 1473, 'gordon': 687, 'trampoline': 1670, 'difference': 417, 'padded': 1138, 'serve': 1430, 'propel': 1256, 'permit': 1177, 'member': 997, 'aired': 45, 'spike': 1506, 'tv': 1683, 'expanded': 552, 'china': 247, 'social': 1485, 'communal': 293, 'environment': 513, 'demographic': 392, 'seen': 1418, 'recreational': 1306, 'extracurricular': 560, 'intramural': 836, 'notable': 1082, 'institution': 817, 'trained': 1666, 'fundamental': 645, 'undergo': 1689, 'endurance': 505, 'exercise': 548, 'ethic': 523, 'prepared': 1235, 'clinic': 263, 'improving': 781, 'educational': 483, 'learning': 907, 'includes': 788, 'disabled': 425, 'deaf': 375, 'relies': 1332, 'signing': 1462, 'communication': 294, 'sporting': 1512, 'happens': 725, 'purpose': 1266, 'catalyst': 218, 'socialization': 1486, 'incidence': 784, 'geographically': 664, 'population': 1211, 'wheelchair': 1768, 'practiced': 1226, 'functional': 644, 'classification': 260, 'reflects': 1318, 'performance': 1171, 'elite': 493, 'female': 581, 'give': 674, 'analysis': 74, 'resource': 1352, 'testing': 1617, 'observation': 1088, 'process': 1247, 'biddy': 161, 'minor': 1018, 'formal': 618, 'globe': 678, 'gay': 657, 'lgbtqia': 918, 'outgames': 1126, 'eurogames': 525, 'midnight': 1012, 'initiative': 811, 'curb': 361, 'inner': 813, 'crime': 349, 'elsewhere': 494, 'engaging': 506, 'urban': 1707, 'alternative': 64, 'drug': 465, 'rezball': 1363, 'reservation': 1349, 'avid': 119, 'native': 1059, 'fantasy': 570, 'popularized': 1210, 'com': 281, 'yahoo': 1800, 'model': 1026, 'baseball': 140, 'fictional': 583, 'select': 1420, 'mock': 1025, 'draft': 456, 'trade': 1664, 'calculate': 202, 'real': 1287, 'see': 1415, 'glossary': 680, 'index': 793, 'list': 929, 'timeline': 1640, 'uleb': 1687, 'ligues': 921, 'européennes': 529, 'english': 508, 'references': 1315, 'citations': 256, 'general': 660, 'reference': 1314, 'external': 558, 'link': 927, 'historical': 744, 'foundation': 630, 'museum': 1046, 'hometown': 752, 'heroes': 737, 'organizations': 1116, 'oldest': 1101, 'source': 1495, 'encyclopædia': 499, 'britannica': 194, 'online': 1104, 'curlie': 362, 'website': 1760, 'statistics': 1535, 'archived': 89, 'wayback': 1756, 'machine': 951, 'plaques': 1195, 'dr': 455}\n",
            "col_names= ['aau' 'aba' 'abdul' ... 'zealand' 'zone' 'šarūnas']\n",
            "SPARSE MATRIX\n",
            "   (0, 146)\t1\n",
            "  (3, 1602)\t1\n",
            "  (4, 1511)\t1\n",
            "  (8, 1602)\t1\n",
            "  (11, 292)\t1\n",
            "  (14, 1199)\t1\n",
            "  (17, 1111)\t1\n",
            "  (19, 78)\t1\n",
            "  (22, 1308)\t1\n",
            "  (23, 339)\t1\n",
            "  (25, 296)\t1\n",
            "  (28, 1242)\t1\n",
            "  (29, 1087)\t1\n",
            "  (31, 1450)\t1\n",
            "  (33, 146)\t1\n",
            "  (35, 85)\t1\n",
            "  (37, 783)\t1\n",
            "  (40, 268)\t1\n",
            "  (43, 413)\t1\n",
            "  (47, 384)\t1\n",
            "  (49, 753)\t1\n",
            "  (52, 145)\t1\n",
            "  (54, 783)\t1\n",
            "  (57, 268)\t1\n",
            "  (60, 413)\t1\n",
            "  :\t:\n",
            "  (10958, 146)\t1\n",
            "  (10961, 499)\t1\n",
            "  (10962, 194)\t1\n",
            "  (10963, 1104)\t1\n",
            "  (10965, 146)\t1\n",
            "  (10967, 362)\t1\n",
            "  (10968, 524)\t1\n",
            "  (10969, 1760)\t1\n",
            "  (10970, 146)\t1\n",
            "  (10970, 281)\t1\n",
            "  (10970, 1314)\t1\n",
            "  (10972, 146)\t1\n",
            "  (10973, 1535)\t1\n",
            "  (10975, 74)\t1\n",
            "  (10977, 745)\t1\n",
            "  (10978, 89)\t1\n",
            "  (10979, 578)\t1\n",
            "  (10986, 1756)\t1\n",
            "  (10987, 951)\t1\n",
            "  (10988, 1105)\t1\n",
            "  (10990, 744)\t1\n",
            "  (10991, 1195)\t1\n",
            "  (10993, 455)\t1\n",
            "  (10994, 849)\t1\n",
            "  (10995, 1051)\t1\n"
          ]
        }
      ],
      "source": [
        "#Wikipedia api\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "#import text data\n",
        "with open('wikipedia_text.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "#create tokens and corpus\n",
        "tokens = word_tokenize(text)\n",
        "corpus = nltk.tokenize.sent_tokenize(text)\n",
        "\n",
        "\n",
        "#lemmetization FIX TO ADD WORDS BACK TO SEPERATE LIST\n",
        "lemmatized_tokens = []\n",
        "for token in tokens:\n",
        "    lemmatized_token = lemmatizer.lemmatize(token)\n",
        "    lemmatized_tokens.append(lemmatized_token)\n",
        "\n",
        "tokens = lemmatized_tokens\n",
        "\n",
        "# remove digits FIX TO ADD WORDS BACK TO SEPERATE LIST\n",
        "def remove_digits(my_string):\n",
        "  clean_string = ''.join([c for c in my_string if not c.isdigit()])\n",
        "  return clean_string\n",
        "\n",
        "no_digit_tokens = []\n",
        "for token in tokens:\n",
        "   no_digit_token = remove_digits(token)\n",
        "   no_digit_tokens.append(no_digit_token)\n",
        "tokens = no_digit_tokens\n",
        "\n",
        "#add stopwords\n",
        "more_stopwords = [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\"]\n",
        "more_stopwords.extend(stopwords.words('english'))\n",
        "\n",
        "#put tokens into vectorizer\n",
        "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b', lowercase=True, stop_words= more_stopwords)\n",
        "Xs = vectorizer.fit_transform(tokens)   \n",
        "print(type(Xs))\n",
        "\n",
        "# VOCABULARY DICTIONARY\n",
        "print(\"vocabulary = \",vectorizer.vocabulary_)   \n",
        "\n",
        "# col_names\n",
        "col_names=vectorizer.get_feature_names_out()\n",
        "print(\"col_names=\",col_names)\n",
        "\n",
        "print(\"SPARSE MATRIX\\n\",Xs)\n",
        "X=np.array(Xs.todense())\n",
        "print(X)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### News API cleaning\n",
        "\n",
        "\n",
        "For this text data I created a string cleaning function did a varitey of things to the text, including replacing multiple copies of punctuation and extra spaces with a single space, removing specific characters like quotes, eliminating duplicate whitespace characters, and converting all the text to lowercase. I applied the function to clean text data from a list of articles, specifically in the \"title\" and \"description\" fields. The cleaned text was then stored in the \"cleaned_data\" list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "#news API\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "baseURL = \"https://newsapi.org/v2/everything?\"\n",
        "total_requests=2\n",
        "verbose=True\n",
        "\n",
        "API_KEY='306919e989964d6ba9f61a0b153c64ba'\n",
        "TOPIC='Basketball'\n",
        "\n",
        "#Query\n",
        "URLpost = {'apiKey': API_KEY,\n",
        "            'q': '+'+TOPIC,\n",
        "            'sortBy': 'relevancy',\n",
        "            'totalRequests': 1}\n",
        "\n",
        "\n",
        "response = requests.get(baseURL, URLpost) #request data from the server\n",
        "response = response.json() #extract txt data from request into json\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d-H%H-M%M-S%S\")\n",
        " \n",
        "with open(timestamp+'-newapi-raw-data.json', 'w') as outfile:\n",
        "    json.dump(response, outfile, indent=4)\n",
        "\n",
        "#cleaning funtion\n",
        "def string_cleaner(input_string):\n",
        "    try: \n",
        "        out=re.sub(r\"\"\"\n",
        "                    [,.;@#?!&$-]+  \n",
        "                    \\ *           \n",
        "                    \"\"\",\n",
        "                    \" \",          \n",
        "                    input_string, flags=re.VERBOSE)\n",
        "\n",
        "        out = re.sub('[’.]+', '', input_string)\n",
        "\n",
        "        out = re.sub(r'\\s+', ' ', out)\n",
        "\n",
        "        out=out.lower()\n",
        "    except:\n",
        "        print(\"ERROR\")\n",
        "        out=''\n",
        "    return out\n",
        "\n",
        "#cleaning\n",
        "\n",
        "article_list=response['articles']  \n",
        "article_keys=article_list[0].keys()\n",
        "index=0\n",
        "cleaned_data=[];  \n",
        "for article in article_list:\n",
        "    tmp=[]\n",
        "    \n",
        "\n",
        "    for key in article_keys:\n",
        "        \n",
        "\n",
        "        if(key=='title'):\n",
        "            tmp.append(string_cleaner(article[key]))\n",
        "\n",
        "        if(key=='description'):\n",
        "             tmp.append(string_cleaner(article[key]))\n",
        "\n",
        "\n",
        "    cleaned_data.append(tmp)\n",
        "    index+=1"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
